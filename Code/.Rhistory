#             max_price = max(sell_price)) %>%
#   mutate(var_price = (max_price - min_price)/ mean_price)
foo <- stat_prices %>%
distinct(id, sell_price) %>%
group_by(id) %>%
summarise(mean_price = mean(sell_price),
min_price = min(sell_price),
max_price = max(sell_price),
ct = n()) %>%
mutate(var_price = (max_price - min_price)/ mean_price)# %>%
# separate(id, into = c("cat", "dept", "item", "state", "store"), sep = "_")
p2 <- foo %>%
ggplot(aes(ct)) +
#  geom_boxplot() +
#  geom_jitter(height = 0.1) +
scale_x_log10(breaks = c(1, 2, 5, 10, 20)) +
geom_density(fill = "red",bw = 0.2, alpha = 0.5) +
theme_hc() +
theme(legend.position = "bottom") +
labs( fill = "", title = "b) Number of Price changes")
p3 <- foo %>%
ggplot(aes(mean_price)) +
geom_density(fill = "darkgreen")  +
theme_hc() +
theme(axis.text.y = element_blank(), legend.position = "none") +
labs(x = "Price [$]", y = "", title = "c) Density: Mean item price")
p4 <- foo %>%
ggplot(aes(var_price)) +
geom_density(fill = "green3")  +
scale_x_continuous(labels = scales::percent) +
coord_cartesian(xlim = c(0, 2)) +
theme_hc() +
theme(axis.text.y = element_blank(), legend.position = "none") +
labs(x = "", y = "", title = "d) Density: Normalised price variations")
jpeg(file="../Figures/general_price_stats.png",width = 700,height = 700)
(p1 + p2) / (p3 + p4)
dev.off()
p1 <- stat_zero %>%
ggplot(aes(mean)) +
geom_density(fill = "blue", bw = 0.02) +
scale_x_continuous(labels = scales::percent) +
coord_cartesian(xlim = c(0, 1)) +
theme_hc() +
theme(axis.text.y = element_blank()) +
labs(x = "", y = "", title = "a) Density: Percentage of zero values")
# p2 <- stat_mean %>%
#   ggplot(aes(mean)) +
#   geom_density(fill = "red", bw = 0.03) +
#   scale_x_log10(breaks = c(1, 2, 5, 10, 20)) +
#   theme_hc() +
#   theme(axis.text.y = element_blank()) +
#   labs(x = "Sales", y = "", title = "Density: Mean sales (w/o zeros; log scale)")
# foo <- stat_prices %>%
#   distinct(id, sell_price) %>%
#   group_by(id) %>%
#   summarise(mean_price = mean(sell_price),
#             min_price = min(sell_price),
#             max_price = max(sell_price)) %>%
#   mutate(var_price = (max_price - min_price)/ mean_price)
foo <- stat_prices %>%
distinct(id, sell_price) %>%
group_by(id) %>%
summarise(mean_price = mean(sell_price),
min_price = min(sell_price),
max_price = max(sell_price),
ct = n()) %>%
mutate(var_price = (max_price - min_price)/ mean_price)# %>%
# separate(id, into = c("cat", "dept", "item", "state", "store"), sep = "_")
p2 <- foo %>%
ggplot(aes(ct)) +
#  geom_boxplot() +
#  geom_jitter(height = 0.1) +
scale_x_log10(breaks = c(1, 2, 5, 10, 20)) +
geom_density(fill = "red",bw = 0.2, alpha = 0.5) +
theme_hc() +
theme(legend.position = "bottom") +
labs( fill = "", title = "b) Number of Price changes")
p3 <- foo %>%
ggplot(aes(mean_price)) +
geom_density(fill = "darkgreen")  +
theme_hc() +
theme(axis.text.y = element_blank(), legend.position = "none") +
labs(x = "Price [$]", y = "", title = "c) Density: Mean item price")
p4 <- foo %>%
ggplot(aes(var_price)) +
geom_density(fill = "green3")  +
scale_x_continuous(labels = scales::percent) +
coord_cartesian(xlim = c(0, 2)) +
theme_hc() +
theme(axis.text.y = element_blank(), legend.position = "none") +
labs(x = "", y = "", title = "d) Density: Normalised price variations")
# jpeg(file="../Figures/general_price_stats.png",width = 700,height = 700)
(p1 + p2) / (p3 + p4)
# dev.off()
p2 <- foo %>%
ggplot(aes(ct)) +
#  geom_boxplot() +
#  geom_jitter(height = 0.1) +
scale_x_log10(breaks = c(1, 2, 5, 10, 20)) +
geom_density(fill = "red",bw = 0.2, alpha = 0.5) +
theme_hc() +
theme(legend.position = "bottom") +
labs( x = "",y = "", fill = "", title = "b) Number of Price changes")
p1 <- stat_zero %>%
ggplot(aes(mean)) +
geom_density(fill = "blue", bw = 0.02) +
scale_x_continuous(labels = scales::percent) +
coord_cartesian(xlim = c(0, 1)) +
theme_hc() +
theme(axis.text.y = element_blank()) +
labs(x = "", y = "", title = "a) Density: Percentage of zero values")
# p2 <- stat_mean %>%
#   ggplot(aes(mean)) +
#   geom_density(fill = "red", bw = 0.03) +
#   scale_x_log10(breaks = c(1, 2, 5, 10, 20)) +
#   theme_hc() +
#   theme(axis.text.y = element_blank()) +
#   labs(x = "Sales", y = "", title = "Density: Mean sales (w/o zeros; log scale)")
# foo <- stat_prices %>%
#   distinct(id, sell_price) %>%
#   group_by(id) %>%
#   summarise(mean_price = mean(sell_price),
#             min_price = min(sell_price),
#             max_price = max(sell_price)) %>%
#   mutate(var_price = (max_price - min_price)/ mean_price)
foo <- stat_prices %>%
distinct(id, sell_price) %>%
group_by(id) %>%
summarise(mean_price = mean(sell_price),
min_price = min(sell_price),
max_price = max(sell_price),
ct = n()) %>%
mutate(var_price = (max_price - min_price)/ mean_price)# %>%
# separate(id, into = c("cat", "dept", "item", "state", "store"), sep = "_")
p2 <- foo %>%
ggplot(aes(ct)) +
#  geom_boxplot() +
#  geom_jitter(height = 0.1) +
scale_x_log10(breaks = c(1, 2, 5, 10, 20)) +
geom_density(fill = "red",bw = 0.2, alpha = 0.5) +
theme_hc() +
theme(legend.position = "bottom") +
labs( x = "",y = "", fill = "", title = "b) Number of Price changes")
p3 <- foo %>%
ggplot(aes(mean_price)) +
geom_density(fill = "darkgreen")  +
theme_hc() +
theme(axis.text.y = element_blank(), legend.position = "none") +
labs(x = "Price [$]", y = "", title = "c) Density: Mean item price")
p4 <- foo %>%
ggplot(aes(var_price)) +
geom_density(fill = "green3")  +
scale_x_continuous(labels = scales::percent) +
coord_cartesian(xlim = c(0, 2)) +
theme_hc() +
theme(axis.text.y = element_blank(), legend.position = "none") +
labs(x = "", y = "", title = "d) Density: Normalised price variations")
# jpeg(file="../Figures/general_price_stats.png",width = 700,height = 700)
(p1 + p2) / (p3 + p4)
# dev.off()
p1 <- stat_zero %>%
ggplot(aes(mean)) +
geom_density(fill = "blue", bw = 0.02) +
scale_x_continuous(labels = scales::percent) +
coord_cartesian(xlim = c(0, 1)) +
theme_hc() +
theme(axis.text.y = element_blank()) +
labs(x = "", y = "", title = "a) Density: Percentage of zero values")
# p2 <- stat_mean %>%
#   ggplot(aes(mean)) +
#   geom_density(fill = "red", bw = 0.03) +
#   scale_x_log10(breaks = c(1, 2, 5, 10, 20)) +
#   theme_hc() +
#   theme(axis.text.y = element_blank()) +
#   labs(x = "Sales", y = "", title = "Density: Mean sales (w/o zeros; log scale)")
# foo <- stat_prices %>%
#   distinct(id, sell_price) %>%
#   group_by(id) %>%
#   summarise(mean_price = mean(sell_price),
#             min_price = min(sell_price),
#             max_price = max(sell_price)) %>%
#   mutate(var_price = (max_price - min_price)/ mean_price)
foo <- stat_prices %>%
distinct(id, sell_price) %>%
group_by(id) %>%
summarise(mean_price = mean(sell_price),
min_price = min(sell_price),
max_price = max(sell_price),
ct = n()) %>%
mutate(var_price = (max_price - min_price)/ mean_price)# %>%
# separate(id, into = c("cat", "dept", "item", "state", "store"), sep = "_")
p2 <- foo %>%
ggplot(aes(ct)) +
#  geom_boxplot() +
#  geom_jitter(height = 0.1) +
scale_x_log10(breaks = c(1, 2, 5, 10, 20)) +
geom_density(fill = "red",bw = 0.2, alpha = 0.5) +
theme_hc() +
theme(legend.position = "bottom") +
labs( x = "",y = "", fill = "", title = "b) Number of Price changes")
p3 <- foo %>%
ggplot(aes(mean_price)) +
geom_density(fill = "darkgreen")  +
theme_hc() +
theme(axis.text.y = element_blank(), legend.position = "none") +
labs(x = "Price [$]", y = "", title = "c) Density: Mean item price")
p4 <- foo %>%
ggplot(aes(var_price)) +
geom_density(fill = "green3")  +
scale_x_continuous(labels = scales::percent) +
coord_cartesian(xlim = c(0, 2)) +
theme_hc() +
theme(axis.text.y = element_blank(), legend.position = "none") +
labs(x = "", y = "", title = "d) Density: Normalised price variations")
jpeg(file="../Figures/general_price_stats.png",width = 700,height = 700)
(p1 + p2) / (p3 + p4)
dev.off()
p1 <- stat_zero %>%
ggplot(aes(mean)) +
geom_density(fill = "blue", bw = 0.02) +
scale_x_continuous(labels = scales::percent) +
coord_cartesian(xlim = c(0, 1)) +
theme_hc() +
theme(axis.text.y = element_blank()) +
labs(x = "", y = "", title = "a) Density: Percentage of zero values")
# p2 <- stat_mean %>%
#   ggplot(aes(mean)) +
#   geom_density(fill = "red", bw = 0.03) +
#   scale_x_log10(breaks = c(1, 2, 5, 10, 20)) +
#   theme_hc() +
#   theme(axis.text.y = element_blank()) +
#   labs(x = "Sales", y = "", title = "Density: Mean sales (w/o zeros; log scale)")
# foo <- stat_prices %>%
#   distinct(id, sell_price) %>%
#   group_by(id) %>%
#   summarise(mean_price = mean(sell_price),
#             min_price = min(sell_price),
#             max_price = max(sell_price)) %>%
#   mutate(var_price = (max_price - min_price)/ mean_price)
foo <- stat_prices %>%
distinct(id, sell_price) %>%
group_by(id) %>%
summarise(mean_price = mean(sell_price),
min_price = min(sell_price),
max_price = max(sell_price),
ct = n()) %>%
mutate(var_price = (max_price - min_price)/ mean_price)# %>%
# separate(id, into = c("cat", "dept", "item", "state", "store"), sep = "_")
p2 <- foo %>%
ggplot(aes(ct)) +
#  geom_boxplot() +
#  geom_jitter(height = 0.1) +
scale_x_log10(breaks = c(1, 2, 5, 10, 20)) +
geom_density(fill = "red",bw = 0.2, alpha = 0.5) +
theme_hc() +
theme(legend.position = "bottom") +
labs( x = "",y = "", fill = "", title = "b) Density: Number of Price changes")
p3 <- foo %>%
ggplot(aes(mean_price)) +
geom_density(fill = "darkgreen")  +
theme_hc() +
theme(axis.text.y = element_blank(), legend.position = "none") +
labs(x = "Price [$]", y = "", title = "c) Density: Mean item price")
p4 <- foo %>%
ggplot(aes(var_price)) +
geom_density(fill = "green3")  +
scale_x_continuous(labels = scales::percent) +
coord_cartesian(xlim = c(0, 2)) +
theme_hc() +
theme(axis.text.y = element_blank(), legend.position = "none") +
labs(x = "", y = "", title = "d) Density: Normalised price variations")
jpeg(file="../Figures/general_price_stats.png",width = 700,height = 700)
(p1 + p2) / (p3 + p4)
dev.off()
mean_price_all_items <- mean_price$mean_price
mean_price <- stat_prices %>%
distinct(id, sell_price) %>%
group_by(id) %>%
summarise(mean_price = mean(sell_price))
mean_price_all_items <- mean_price$mean_price
mean_price <- foo$mean_price
mean_price_all_items <- mean(mean_price)
# # Filter out rows where sales and sell_price are not NA
# # Load the merged data
merged_data2 <- read.csv("../Data/merged_data.csv")
cleaned_data <- merged_data2 %>% filter(!is.na(sales)  & is.na(sell_price))
summary(merged_data2)
merged_data2 <- merged_data2 %>%
mutate(
date = as.Date(date),
wm_yr_wk = as.double(wm_yr_w/k),
weekday = as.character(weekday),
wday = as.double(wday),
month = as.double(month),
year = as.double(year),
event_name_1 = as.character(event_name_1),
event_type_1 = as.character(event_type_1),
event_name_2 = as.character(event_name_2),
event_type_2 = as.character(event_type_2),
snap_TX = as.double(snap_TX),
item_id = as.character(item_id),
sales = as.double(sales),
sell_price = as.double(sell_price)
)
merged_data2 <- merged_data2 %>%
mutate(
date = as.Date(date),
wm_yr_wk = as.double(wm_yr_wk),
weekday = as.character(weekday),
wday = as.double(wday),
month = as.double(month),
year = as.double(year),
event_name_1 = as.character(event_name_1),
event_type_1 = as.character(event_type_1),
event_name_2 = as.character(event_name_2),
event_type_2 = as.character(event_type_2),
snap_TX = as.double(snap_TX),
item_id = as.character(item_id),
sales = as.double(sales),
sell_price = as.double(sell_price)
)
#
# # Check the data types
# str(merged_data2)
# ts_data <- as_tsibble(merged_data2, index = date, key = item_id)
# Calculate overall correlation for all products
overall_correlation <- cor(merged_data$sales, merged_data$sell_price, use = "complete.obs")
correlation_by_product <- merged_data %>%
group_by(item_id) %>%
filter(complete.cases(sales, sell_price)) %>%
summarize(correlation = cor(sales, sell_price))|>arrange(correlation)
# Calculate overall correlation for all products
overall_correlation <- cor(merged_data$sales, merged_data$sell_price, use = "pairwise.complete.obs")
correlation_by_product <- merged_data %>%
group_by(item_id) %>%
filter(complete.cases(sales, sell_price)) %>%
summarize(correlation = cor(sales, sell_price))|>arrange(correlation)
# Calculate overall correlation for all products
overall_correlation <- cor(merged_data$sales, merged_data$sell_price, use = "complete.obs")
correlation_by_product <- merged_data %>%
group_by(item_id) %>%
filter(complete.cases(sales, sell_price)) %>%
summarize(correlation = cor(sales, sell_price))|>arrange(correlation)
#ALL items - forecasting with prophet
# set.seed(123)  # Set seed for reproducibility
# random_items <- sample(unique(merged_data$item_id), 50)
#
# Convert categorical variables to dummy variables
merged_full_all <- fastDummies::dummy_cols(merged_data %>%  mutate(across(c("event_name_1", "event_name_2", "event_type_1", "event_type_2"), ~replace(., is.na(.), "None"))), select_columns = c("event_name_1", "event_type_1", "event_name_2", "event_type_2")) %>%
as_tsibble(key = item_id, index = date) %>%
mutate(sell_price = ifelse(is.na(sell_price), 0, sell_price))
# filter(item_id %in% randmerged_full_all) %>%
colnames(merged_full_all) <- gsub(" ", "_", colnames(merged_full_all))
colnames(merged_full_all) <- gsub("-", "_", colnames(merged_full_all))
colnames(merged_full_all) <- gsub("'", "_", colnames(merged_full_all))
# write.csv(merged_full_all,"../Data/merged_full_all.csv", row.names=FALSE)
# Select only dummy variables
dummy_vars <- select(merged_full_all, starts_with("event_name_1_"), starts_with("event_type_1_"), starts_with("event_name_2_"), starts_with("event_type_2_"))
# Exclude date and item_id columns
dummy_vars <- dummy_vars[, !colnames(dummy_vars) %in% c("date", "item_id")]
colnames(dummy_vars) <- str_trim(colnames(dummy_vars))
dummy_cols <- colnames(dummy_vars)
# print(dummy_cols)
# Escape column names with spaces
dummy_cols <- paste0("`", dummy_cols, "`")
# Create the string format
regressor_string <- paste(dummy_cols, collapse = " + ")
# print(regressor_string)
# Include the string in the formula
sales_formula <- formula(paste("sales ~ sell_price + snap_TX + ", regressor_string,
"+ season(period = 'week', order = 10, type = 'multiplicative')",
"+ season(period = 'year', order = 10, type = 'multiplicative')"))
# print(regressor_string)
# Fit the model
fit <- merged_full_all |>
model(prophet = prophet(sales_formula))
# Generate the future dataframe
merged_future_all <- new_data(merged_full_all, 28)
# Get wm_yr_wk
merged_future_all <- merged_future_all %>%
left_join(calendar %>% select(wm_yr_wk, date), by = c("date"))
# Merge prices by wm_yr_wk, item_id
merged_future_all <- merged_future_all %>%
left_join(sell_prices %>% select(wm_yr_wk, item_id, sell_price), by = c("wm_yr_wk", "item_id")) %>%
mutate(sell_price = ifelse(is.na(sell_price), 0, sell_price))
# Convert categorical variables to dummy variables
calendar_dummies <- fastDummies::dummy_cols(calendar %>%
mutate(across(c("event_name_1", "event_name_2", "event_type_1", "event_type_2"), ~replace(., is.na(.), "None"))), select_columns = c("event_name_1", "event_type_1", "event_name_2", "event_type_2"))
colnames(calendar_dummies) <- gsub(" ", "_", colnames(calendar_dummies))
colnames(calendar_dummies) <- gsub("-", "_", colnames(calendar_dummies))
colnames(calendar_dummies) <- gsub("'", "_", colnames(calendar_dummies))
merged_future_all <- merged_future_all |> inner_join(calendar_dummies , by = "date")#%>% select(date,event_name_1,event_type_1,event_name_2,event_type_2,snap_TX)
# glance(fit)
write.csv(merged_future_all,"../Data/merged_future_all.csv", row.names=FALSE)
# Forecast
fc <- forecast(fit, new_data =  merged_future_all)
write.csv(fc,"../Data/fc_all.csv", row.names=FALSE)
# fc |>
#   autoplot(merged_full_selected,level=NULL) +
#   labs(x = "Date", y = "Sales")
#Check metrics with test
sales_test_validation_long <- sales_test_validation %>%
pivot_longer(cols = -id, names_to = "date", values_to = "sales") %>%
mutate(date = as.Date("2011-01-29") + as.integer(str_remove(date, "d_")) - 1) %>%
rename(item_id = id) %>%
mutate(item_id = str_remove(item_id, "_TX_3_validation"))%>%
as_tsibble(key = item_id, index = date)#|>
# filter(item_id %in% random_items)
metrics_by_product <- fc %>%
accuracy(sales_test_validation_long) %>%
group_by(item_id) %>%
summarise(
mae = mean(MAE, na.rm = TRUE),
acf1 = mean(ACF1, na.rm = TRUE),
rmse = mean(RMSE, na.rm = TRUE)
)
metrics <- fc %>%
accuracy(sales_test_validation_long) %>%
summarise(
mae = mean(MAE, na.rm = TRUE),
acf1 = mean(ACF1, na.rm = TRUE),
rmse = mean(RMSE, na.rm = TRUE)
)
# round the predictions
prediction_data <- fc %>%
select(.mean, sales, item_id, date) %>%
mutate(.mean = pmax(.mean, 0),  # Replace negative values with 0
rounded_predictions = round(.mean)) %>%
as_tsibble(index = date, key = item_id)
# Calculate RMSE with rounded predictions
calculate_rmse <- function(pred_tsibble, true_tsibble) {
# Assuming the tsibble has a column named 'value' for both predicted and true values
pred_df <- as.data.frame(pred_tsibble)
true_df <- as.data.frame(true_tsibble)
# Make sure the order is the same
pred_df <- pred_df[order(pred_df$date, pred_df$item_id), ]
true_df <- true_df[order(true_df$date, true_df$item_id), ]
# Extract values
pred_values <- as.vector(pred_df$rounded_predictions)
true_values <- as.vector(true_df$sales)
# Calculate RMSE
rmse <- sqrt(mean((pred_values - true_values)^2, na.rm = TRUE))
return(rmse)
}
rmse_result_rounded <- calculate_rmse(prediction_data, sales_test_validation_long)
# Add rmse_result_rounded to metrics
metrics <- metrics %>%
add_column(
rmse_rounded = rmse_result_rounded
)
# write.csv(sales_test_validation_long,"../Data/sales_test_validation_long.csv", row.names=FALSE)
# metrics <- fc |> accuracy(sales_test_validation_long)
write.csv(metrics,"../Data/metrics_prophet_all.csv", row.names=FALSE)
write.csv(metrics_by_product,"../Data/metrics_by_product_prophet_all.csv", row.names=FALSE)
# Create submission csv
prediction_data <- fc %>%
select(.mean, sales, item_id, date) %>%
mutate(.mean = pmax(.mean, 0),  # Replace negative values with 0
rounded_predictions = round(.mean)) %>%
as_tsibble(index = date, key = item_id)
# Convert to data frame and drop the 'mean' and 'sales' columns
prediction_df <- as.data.frame(prediction_data)
prediction_df <- prediction_df[, !(names(prediction_df) %in% c(".mean", "sales"))]
wide_prediction <- prediction_df %>%
spread(key = "item_id", value = "rounded_predictions")
# Transpose the table
wide_prediction <- as.data.frame(t(wide_prediction))
# Optionally, rename the columns
colnames(wide_prediction) <- c(paste0("F", 1:28))
wide_prediction <- wide_prediction[-1, ]
wide_prediction$id <- rownames(wide_prediction)
# Add "_TX_3_validation" to each ID
wide_prediction$id <- paste0(wide_prediction$id, "_TX_3_validation")
# Move the last column to the first
wide_prediction <- wide_prediction[, c(ncol(wide_prediction), 1:(ncol(wide_prediction)-1))]
#Reset index
rownames(wide_prediction) <- NULL
write.csv(wide_prediction,"../Data/wide_prediction_all.csv", row.names=FALSE)
View(wide_prediction)
library('stringr') # string manipulation
library('vroom') # input/output
library(fpp3)
library(latex2exp)
library(rmarkdown)
library(skimr)
library(dplyr)
library(tsibble)
library(forecast)
library(stats)
library(ggplot2)
library(fable)
library(fable.prophet)
library(fabletools)
library(cowplot)
library(fastDummies)
library(modeltime)
#---------------------LOAD DATASETS---------------------
path = 'C:/Users/dimcp/Documents/AFCS-Project/Data/'
sell_prices <- vroom(str_c(path,"sell_prices_afcs2023.csv"), delim = ",", col_types = cols())
sales_train_validation <- vroom(str_c(path,"sales_train_validation_afcs2023.csv"), delim = ",", col_types = cols())
calendar <- vroom(str_c(path,"calendar_afcs2023.csv"), delim = ",", col_types = cols())
sales_test_validation <- vroom(str_c(path,"sales_test_validation_afcs2022.csv"), delim = ",", col_types = cols())
samples_submission <- vroom(str_c(path,"sample_submission_afcs2023.csv"), delim = ",", col_types = cols())
extract_ts <- function(df){
min_date <- as.Date("2011-01-29") #lowest data, corresponds to d_1
df %>%
select(id, starts_with("d_")) %>%   #take the id of the item and the daily sales columns
pivot_longer(starts_with("d_"), names_to = "dates", values_to = "sales") %>%     #reshape
mutate(dates = as.integer(str_remove(dates, "d_"))) %>%
mutate(dates = min_date + dates - 1) %>%         #turn day numbers into dates
mutate(id = str_remove(id, "_validation"))       #remove end of item id
}
